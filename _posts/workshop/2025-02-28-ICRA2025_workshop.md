---
event_name: ICRA 2025 Workshop
title: ICRA 2025 Workshop
description: How do Robots Care - Innovative Strategies and Interface for Physically Assistive Robots in Healthcare
group: event
image: images/event_img/icra2025/ICRA-ATL-logo.webp
date_start: 2025-05-19 8:30 AM
date_end: 2025-05-19 5:30 PM
connection_link: https://2025.ieee-icra.org/
titleimg: /images/event_img/icra2025/icra_2025_titleimg_sample.png
---

{%
  include figure.html
  image="images/event_img/icra2025/cover_25.png"
%}

***

Dear Colleagues,

We are pleased to announce the Call for Papers for our workshop, "How do Robots Care? Innovative Strategies and Interfaces for Physically Assistive Robots in Healthcare," which will be held during the IEEE International Conference on Robotics and Automation (ICRA) 2025 in Atlanta, USA, from May 19–23, 2025.

This workshop aims to advance the development of innovative and user-centric solutions for physically assistive robots in healthcare. We are seeking contributions that explore cutting-edge research and practical applications.

Submission Guidelines
We invite researchers and practitioners to submit **Extended Abstracts (2–4 pages)** or **Videos (max. 3min)**. Papers will undergo double-blind peer review, and selected works may be asked for oral presentations and/or poster sessions during the workshop.

We will address a diverse range of **topics** related to the theme of the workshop, including but not limited to:
* Monitoring of human cognitive and physical ergonomics
* Modeling of humans with mobility constraints
* Human movement and gait analysis
* Prediction of human intentions and actions
* Assessment of trust, comfort, and perceived safety in pHRI
* Human-centered design of physically assistive devices and interfaces
* Smart walking and mobility aids
* Customizable interfaces for physical assistance
* Co-adaptation and personalization of physically assistive robots
* Model-based and model-free control strategies for physical assistance
* Robot learning from human-human physical interaction
* Planning and decision-making for physical assistance
* Safety and robustness in physical assistance
* Design of explainable and trustworthy assistive behaviors \\
Challenges and requirements of in-home and in-hospital deployment of physically assistive robots
You can submit your contribution [here](https://docs.google.com/forms/d/e/1FAIpQLSfWteJxQAsAcowR1rqxx6C8m2Xzjo-4ugzbTl3FBOPu-xO00w/viewform).

## Important Dates
* **Submission Deadline:** 24th March 2025
* **Notification of Acceptance:** 3rd April 2025
* **Camera-ready Submissions:** 1st May 2025
* **Workshop Date:** May 19–23, 2025

## Why submitting?
* Share your research with a global audience and gain visibility. 
* Engage with leading experts and peers in the field. 
* Explore collaboration opportunities.
* Enjoy the talks of our esteemed speakers and discuss with them.
* Enjoy live demonstrations.
* Be eligible for the Best Paper, Best Poster/Presentation, or Best Video awards, funded by our distinguished sponsors.
* Visit the workshop website for more information about the workshop and submission details.

We look forward to receiving your contributions and seeing you at ICRA 2025!


This workshop is sponsored by

- [IEEE-RAS Technical Committee on Rehabilitation and Assistive Robotics](https://www.ieee-ras.org/rehabilitation-and-assistive-robotics)
- [IEEE-RAS Technical Committee for Cognitive Robotics](https://www.ieee-ras.org/cognitive-robotics)
- [International Consortium for Rehabilitation Robotics (ICORR)](https://icorr-c.org/)


***

<!-- ***
## <i class="fas fa-play-circle"></i>**Teaser Video** -->

<!-- Extract the html code from Youtube "share","퍼가기" -->
<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/EjHqnF74KZg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> -->

<!-- *** -->

## Programs
<style>
  table {
    width: 100%;
    table-layout: fixed;
    border-collapse: collapse;
  }
  th, td {
    word-wrap: break-word; /* Add padding to the content for better spacing */
  }
  th:nth-child(1), td:nth-child(1) {
    width: 15%; /* Adjust the width for the "Time" column */
  }
  th:nth-child(2), td:nth-child(2) {
    width: 20%; /* Adjust the width for the "Talk" column */
  }
  th:nth-child(3), td:nth-child(3) {
    width: 65%; /* Adjust the width for the "Title / Comments" column */
  }
</style>


<table>

  <tr>
    <th scope="col">Time</th>
    <th scope="col">Talk</th>
    <th scope="col">Title / Comments</th>
  </tr>


  <tr>
    <td align="center">08:45 – 09:00</td>
    <td align="center">-</td>
    <td>Introduction by the Organizers</td>
  </tr>
  <tr>
    <td align="center">09:00 – 09:30</td>
    <td align="center"><b>ESascha Wischniewski & Patricia Rosen</b></td>
    <td>Real-time Monitoring and Modelling of Workload - Opportunities and Risks from an Occupational Safety and Health (OSH) Perspective</td>
  </tr>
  <tr>
    <td align="center">09:30 – 10:00</td>
    <td align="center"><b>Seunghoon Hwang</b></td>
    <td>Quantitative Characterization of Human Joint Biomechanics and Its Applications</td>
  </tr>
  <tr>
    <td align="center">10:00 – 10:30</td>
    <td align="center"><b>-</b></td>
    <td>Round Table</td>
  </tr>
  <tr>
    <td align="center">10:30 – 11:00</td>
    <td align="center">-</td>
    <td>Coffee Break and Demo Session</td>
  </tr>
  
  <tr>
    <td align="center">11:00 – 11:30</td>
    <td align="center"><b>Ana Luisa Trejos</b></td>
    <td>Advances in Soft Sensors and Actuators within Wearable Mechatronic Devices for Motion Assistance</td>
  </tr>
  <tr>
    <td align="center">11:30 – 11:50</td>
    <td align="center"><b>Jee-Hwan Ryu</b></td>
    <td>Twisted String Actuator-based Soft Exo-suits</td>
  </tr>

  <tr>
    <td align="center">11:50 – 12:30</td>
    <td align="center">-</td>
    <td>Round Table</td>
  </tr>

  <tr>
    <td align="center">12:30 – 13:30</td>
    <td align="center"><b>-</b></td>
    <td>Lunch Break and Demo Session</td>
  </tr>

  <tr>
    <td align="center">13:30 – 14:00</td>
    <td align="center"><b>-</b></td>
    <td>Extended Abstracts Presentation</td>
  </tr>

  <tr>
    <td align="center">14:00 – 14:30</td>
    <td align="center"><b>Maya Cakmak</b></td>
    <td>Talk TBD</td>
  </tr>

  <tr>
    <td align="center">14:30 – 15:00</td>
    <td align="center"><b>-</b></td>
    <td>Coffee Break and Poster Session</td>
  </tr>

  <tr>
    <td align="center">15:00 – 15:30</td>
    <td align="center"><b>Tapomayukh Bhattacharjee</b></td>
    <td>Towards Robotic Caregiving: Building Robots that Work Alongside Human Stakeholders</td>
  </tr>
  

  <tr>
    <td align="center">15:30 – 16:00</td>
    <td align="center"><b>Alona Kharchenko</b></td>
    <td>Overcoming Hardware Limits: How Collaboration Between the Elderly and Humanoid Robotic Avatars Enhances Home Care</td>
  </tr>

  <tr>
    <td align="center">16:00 – 16:30</td>
    <td align="center"><b>-</b></td>
    <td>Panel Discussion</td>
  </tr>

  <tr>
    <td align="center">16:30 – 17:00</td>
    <td align="center">-</td>
    <td>Conclusion and Award Ceremony</td>
  </tr>


  <!-- <tr>
    <td rowspan="4">10.15 – 10.30</td>
    <td>Expanding Example</td>
    <td>-</td>
  </tr>
  <tr>
    <td>Ex</td>
    <td>-</td>
  </tr> 
  <tr>
    <td>Ex</td>
    <td>-</td>
  </tr> 
  <tr>
    <td>Ex</td>
    <td>-</td>
  </tr> 
  <tr>
    <td>10.30 - 12.30</td>
    <td>Example~~</td>
    <td>-</td>
  </tr> -->

</table>
## <i class="far fa-grin"></i> **Orgranizers**



<br>
{%
  include orginizer_description.html
  image="https://www.iit.it/documents/216850/1187541/Luka+Peternel.jpg/85853b89-1498-4495-9ad3-86b47c14dc57?t=1647429490845"
  org_name="Luka Peternel"
  position="Assistant Professor"
  affilation="Delft University of Technology, Netherlands"
  email="L.Peternel@tudelft.nl"
  text="Luka Peternel received a Ph.D. in robotics from Faculty of Electrical Engineering, University of Ljubljana, Slovenia in 2015. He conducted Ph.D. studies at Department of Automation, Biocybernetics and Robotics, Jožef Stefan Institute in Ljubljana from 2011 to 2015, and at Department of Brain-Robot Interface, ATR Computational Neuroscience Laboratories in Kyoto, Japan in 2013 and 2014. He was with Human-Robot Interfaces and Physical Interaction Lab, Advanced Robotics, Italian Institute of Technology in Genoa, Italy from 2015 to 2018. From 2019, Luka Peternel is an Assistant Professor at Department of Cognitive Robotics, Delft University of Technology in the Netherlands."
%}

<br>
{%
  include orginizer_description.html
  image="images/김완수교수님.png"
  org_name="Wansoo Kim"
  position="Assistant Professor"
  affilation="Hanyang University, Republic of Korea"
  email="wansookim@hanyang.ac.kr"
  text="Wansoo Kim is an assistant professor at Hanyang University ERICA, Republic of Korea. He received the B.S. degree in mechanical engineering from Hanyang University, Korea in 2008 and a Ph.D. degree in mechanical engineering from Hanyang University, Korea in 2015 (Integrated MS/PhD program). He was with Human-Robot Interfaces and Physical Interaction Lab, Italian Institute of Technology in Genoa, Italy from 2016 to 2020. He has developed several exoskeleton systems such as HEXAR-Hanyang Exoskeleton Assistive Robot, and conducted research on the control of the powered exoskeleton robot through the physical human-robot interaction (pHRI) forces. He is currently involved in a project Horizon-2020 project SOPHIA. He has contributed to several projects in the field of exoskeleton robot in Korea projects (High responsive control technology of a lower-limb exoskeleton under rough terrain-1415144732, Development of Wearable Robot for Industrial Labor Support-1415135223, etc.), and joint R&D projects with a company (DSME and LIG Nex1). He was the winner of the Solution Award 2019 (Premio Innovazione Robotica at MECSPE2019), the winner of the KUKA Innovation Award 2018, the winner of the HYU best PhD paper award 2015, and the winner of the ICCAS best presentation award 2014. His research interests are in Physical human-robot interaction (pHRI), human-robot collaboration, Shared Control, Ergonomics, Human modelling, Feedback devices, and powered exoskeleton robot."
%}

<br>
{%
  include orginizer_description.html
  image="https://news.asu.edu/sites/default/files/styles/panopoly_image_quarter/public/hani_ben_amor.jpg?itok=OijtZSAp"
  org_name="Heni Ben Amor"
  position="Associate Professor"
  affilation="Arizona State University, USA"
  email="hani.benamor@asu.edu"
  text="Heni Ben Amor received the Ph.D. degree in computer science from the Technical University Freiberg, Freiberg, Germany, in 2010, focusing on artificial intelligence and machine learning.,He is an Associate Professor of Robotics with Arizona State University, Tempe, AZ, USA. He is the Director of the ASU Interactive Robotics Laboratory. He was a Research Scientist with Georgia Tech, Atlanta, GA, USA, a Postdoctoral Researcher with the Technical University Darmstadt, Darmstadt, Germany, and a Visiting Research Scientist with the Intelligent Robotics Lab, University of Osaka, Osaka, Japan. His research interests include machine learning, robotics, human–robot interaction, and virtual reality.,Dr. Amor was the recipient of the NSF CAREER Award, the Fulton Outstanding Assistant Professor Award, as well as the Daimler-and-Benz Fellowship."
%}


<br>
{%
  include orginizer_description.html
  image="https://www.iit.it/documents/216850/1187541/Arash+Ajoudani.jpg/d35fe334-7b6a-7de2-e406-da18b61ba983?t=1647429490780"
  org_name="Arash Ajoudani"
  position="Principal Investigator"
  affilation="Italian Institute of Technology, Italy"
  email="arash.ajoudani@iit.it"
  text="Arash Ajoudani received his PhD degree in Robotics and Automation from Centro 'E Piaggio', University of Pisa, and Advanced Robotics Department (ADVR), Italian Institute of Technology (IIT), Italy (July 2014). His PhD thesis was a finalist for the Georges Giralt PhD award 2015 - best European PhD thesis award in robotics. He is currently a tenure-track scientist and the leader of the Human-Robot Interfaces and Physical Interaction (HRI2) lab of the IIT. He was a winner of the Amazon Research Awards 2019, the winner of the Werob best poster award 2018, winner of the KUKA Innovation Award 2018, a finalist for the best conference paper award at Humanoids 2018, a finalist for the best interactive paper award at Humanoids 2016, a finalist for the best oral presentation award at Automatica (SIDRA) 2014, the winner of the best student paper award and a finalist for the best conference paper award at ROBIO 2013, and a finalist for the best manipulation paper award at ICRA 2012. He is the author of the book 'Transferring Human Impedance Regulation Skills to Robots' in the Springer Tracts in Advanced Robotics (STAR), and several publications in journals, international conferences, and book chapters. He is currently serving as the executive manager of the IEEE-RAS Young Reviewers' Program (YRP), chair and representative of the IEEE-RAS Young Professionals Committee, and co-chair of the IEEE-RAS Member Services Committee. He has been serving as a member of scientific advisory committee and as an associate editor for several international journals and conferences such as IEEE RAL, Biorob, ICORR, etc. His main research interests are in physical human-robot interaction and cooperation, robotic manipulation, robust and adaptive control, rehabilitation robotics, and tele-robotics."
%}

<br>
{%
  include orginizer_description.html
  image="https://www.iit.it/documents/216850/1188327/EiichiYoshida2020.jpg/a11979c3-93f9-caa1-d1cc-088047c9f43e?t=1647438653701"
  org_name="Eiichi Yoshida"
  position="Professor"
  affilation=" Tokyo University of Science, Japan"
  email="eiichi.yoshida@rs.tus.ac.jp"
  text="Eiichi Yoshida received M.E and Ph. D degrees on Precision Machinery Engineering from Graduate School of Engineering, the University of Tokyo in 1996. He then joined former Mechanical Engineering Laboratory, later in 2001 reorganized as National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan. He served as Co-Director of AIST-CNRS JRL (Joint Robotics Laboratory) at LAAS-CNRS, Toulouse, France, from 2004 to 2008, and at AIST, Tsukuba, Japan from 2009 to 2021. He was also Deputy Director of Industrial Cyber-Physical Systems Research Center, and TICO-AIST Cooperative Research Laboratory for Advanced Logistics in AIST from 2020 to 2021. From 2022, he is Professor of Tokyo University of Science, at Department of Applied Electronics, Faculty of Advanced Engineering. He was previously invited as visiting professor at Karlsrule Institute of Technology and University of Tsukuba. He was awarded Chevalier, l’Ordre National du Mérite from French Government in 2016 for his long-term contributions to French-Japanese collaboration on robotics. He is IEEE Fellow, and member of RSJ and JSME. His research interests include robot task and motion planning, human modeling, humanoid robots and advanced logistics."
%}






***
## <i class="fas fa-microphone-alt"></i> **Invited Speakers**

{%
  include invited_speaker.html
  speakername="Eiichi Yoshida"
  position="(Tokyo University of Science, Japan)"
  spekerlink="https://www.tus.ac.jp/ridai/doc/ji/RIJIA01Detail.php?act=pos&kin=ken&diu=7455&pri=en"
  headline="Learning-based Understanding and Prediction of Human Motion for Symbiotic Robot Interaction"

  text="Human-symbiotic robotic behavior needs not only understanding and interpreting human behaviors, but also predicting their intentions. We have been addressing anthropomorphic whole-body motion understanding, basically model-based dynamic or musculo-skeletal analysis. While it is very useful, we have also realized the difficulty of understanding the underlying motion strategy and the synthesize anthropomorphic motions only by this approach. Recent advances on machine learning techniques can be one important key to address those challenges. In this talk, we introduce some recent research activities to leverage learning methodology, on contact detection and human-following robot. We first address contact detection and estimation from motions. Physical human-robot interaction (pHRI) needs to deal with various contacts. We started tacking this issue by variable autoencoder (VAE) to detect contacts and estimate their force at the same time from the motion input only. We introduce another study on a human-following mobile robot, predicting  motions friendly to both the human and robot by combining optimization and machine learning towards smooth interaction. "
%}


{%
  include invited_speaker.html
  speakername="Serena Ivaldi"
  position="(INRIA, France)"
  spekerlink="https://members.loria.fr/SIvaldi/"
  headline="Adaptation in human-robot collaboration"

  text="In this talk, I will present our experimental findings concerning the adaptation mechanisms that humans exhibit when physically interacting with a cobot during co-manipulation tasks. This knowledge is important to inform robotics controller that reason about the human ergonomics during collaboration. I will also show some software tools that we developed to assess and visualise ergonomics criteria online based on Digital Human Models."
%}

{%
  include invited_speaker.html
  speakername="Tadej Petrič"
  position="(Jožef Stefan Institute, Slovenia)"
  spekerlink="http://cobotat.ijs.si/members/tadej-petric/"
  headline="Enhancing human-robot collaboration through investigating human dyads"

  text="In this talk, I will focus on improving human-robot collaboration through investigating human dyads in workspaces. The interaction between humans and robots in shared workspaces presents numerous challenges that must be addressed to optimize their collaboration. In this context, studying human dyads in workspaces provides an effective means to understand and improve human-robot interaction. By exploring the dynamics of human dyads and the factors that influence their collaboration in shared workspaces, we can develop strategies to improve the effectiveness of human-robot collaboration. This talk will provide an overview of my current research on human dyads in workspaces and highlight the potential benefits of this approach for optimizing human-robot collaboration."
%}

{%
  include invited_speaker.html
  speakername="Bram Vanderborght"
  position="(Vrije Universiteit Brussel, Belgium)"
  spekerlink="http://mech.vub.ac.be/multibody/members/bram.htm"
  headline="Industry 5.0: a multidisciplinary research approach?"

  text="Human-robot collaboration has great potential to face societal challenges (as ageing population, need for better and healthier work), sustainability requirements and economic needs (small lot sizes, reshoring,…). In this talk we will focus how we achieve a human centered approach by combining expertise of not only engineering/AI fields, but also human and social sciences. As such we achieve a higher acceptance of the technology by the use. We provide examples on collaborative robots and exoskeletons for improved ergonomics and sustainable self healing soft grippers.  At the VUB this work was performed in the Brussels Human Robotics Research Center, BruBotics, which is a joint initiative of 8 research groups of the Vrije Universiteit Brussel (VUB) sharing a common vision: improve our quality of life through Human centered Robotics."
%}

{%
  include invited_speaker.html
  speakername="Dorsa Sadigh"
  position="(Stanford University, USA)"
  spekerlink="https://dorsa.fyi"
  headline="Learning Representations for Human-Robot Collaboration"

  text="There have been significant advances in the field of robot learning in the past decade. However, many challenges still remain when considering how robot learning can advance interactive agents such as robots that collaborate with humans. In this talk, I will be discussing the role of learning representations for robots that interact with humans and robots that interactively learn from humans through a few different vignettes. I will first discuss how bounded rationality of humans guided us towards developing learned latent action spaces for shared autonomy. It turns out this “bounded rationality” is not a bug and a feature — i.e. we can develop extremely efficient coordination algorithms by learning latent representations of partner strategies and operating in this low dimensional space. I will then discuss how we can go about actively learning such representations capturing human preferences including our recent work on how large language models can help design human preference reward functions. Finally, I will end the talk with a discussion of the type of representations useful for learning a robotics foundation model and some preliminary results on a new model that leverages language supervision to shape representations."
%}

{%
  include invited_speaker.html
  speakername="Xu Xu"
  position="(North Carolina State University, USA)"
  spekerlink="https://www.ise.ncsu.edu/people/xxu/"
  headline="Promote workers’ safety and health through ubiquitous sensing during human-robot collaborative assembly tasks"

  text="In recent years, the topic of ubiquitous sensing has gained significant attention due to the availability of low-cost portable sensors, such as cameras and inertial measurement units. Through the use of ubiquitous sensing, human-centric intelligent systems can collect signals from sensors and perform context-aware computing based on human physical and cognitive activities. This talk will explore various applications of ubiquitous sensing, with a particular focus on promoting safety and health during human-robot collaborative assembly tasks. Specifically, we will discuss three applications: collision avoidance between human workers and collaborative robots, finding an optimal point of operation for robots to minimize the risk of musculoskeletal disorders for workers, and examining the impact of robot factors (such as end-effector movement path) on workers' mental stress."
%}

{%
  include invited_speaker.html
  speakername="Eiichi Yoshida"
  position="(Tokyo University of Science, Japan)"
  spekerlink="https://tus.elsevierpure.com/en/persons/eiichi-yoshida"
  headline="Title"

  text="TBA"
%}

{%
  include invited_speaker.html
  speakername="Dongheui Lee"
  position="(Technische Universität Wien (TU Wien), Austria)"
  spekerlink="https://asl.ict.tuwien.ac.at/team-dongheui-lee.html"
  headline="Decision Making in Physical Human Robot Joint Actions"

  text="In this talk, I will present our recent research in collaborative robots in joint assembly tasks. Especially I will discuss about human’s decision making in joint actions, considering human ergonomics, overall task performances. I will present human user study results in this context."
%}

{%
  include invited_speaker.html
  speakername="Sylvain Calinon"
  position="(Idiap Research Institute, Switzerland)"
  spekerlink="https://calinon.ch"
  headline="Learning from Demonstration for Collaborative Tasks with Physical Contacts"

  text="Collaborative tasks with physical contacts require robot controllers that can swiftly adapt to the ongoing situation. Efficient representations at the crossroad of control, planning and perception are required to facilitate this challenge. Learning from demonstration (LfD) can be exploited to build these representations, either by learning the hyperparameters or by learning the higher level organization. Our ongoing work explores several facets of these challenges. First, I will show that a probabilistic interpretation of optimal control can facilitate the links between learning and optimization. First, I will show that a cost function composed of a sum of quadratic error terms can be treated either as a linear quadratic regulator (LQR) problem from an optimal control perspective, or as a product of Gaussians (PoG) from an information fusion perspective. I will then show that this dual view can be extended to non-quadratic costs and non-linear systems, which can be used to extend the concept of movement primitives to control primitives, bringing a modular approach to (re)combine controllers in parallel and in series. I will finally show that the underlying dictionary of controllers can contain: 1) ergodic control behaviors to provide explorative controllers in which the areas to explore are learned from demonstration; and 2) impedance behaviors exploiting geometry (Riemannian manifold and geometric algebra) for object affordances modeling. The two can be exploited to reduce the number of human demonstrations required and to provide better generalization capability. I will showcase the proposed information fusion principle in a wide range of applications requiring shared control, including teleoperation, haptic guidance and physical assistance.   
  
  Dr Sylvain Calinon is a Senior Research Scientist at the Idiap Research Institute and a Lecturer at the Ecole Polytechnique Fédérale de Lausanne (EPFL). He heads the Robot Learning & Interaction group at Idiap, with expertise in human-robot collaboration, robot learning from demonstration and model-based optimization. The approaches developed in his group can be applied to a wide range of applications requiring manipulation skills, with robots that are either close to us (assistive and industrial robots), parts of us (prosthetics and exoskeletons), or far away from us (shared control and teleoperation)."
%}

{%
  include invited_speaker.html
  speakername="Luis Figueredo"
  position="( Technical University of Munich (TUM), Germany)"
  spekerlink="https://www.mirmi.tum.de/mirmi/team/figueredo-luis/"
  headline="Planning for humans: Leveraging comfort-based manipulability for improved pHRC"

  text="Recent advances in robotics technologies are closing the gap between humans and robots. Nonetheless, robots are still rarely thought of being physically engaging with humans, and human-like physical human-robot collaboration (pHRC) is still one of the key open challenges in robotics research. Collaboration and teamwork are better achieved when members understand each other capabilities and preferences. When it comes to pHRC, that means robots need better reasoning of human's physical capabilities, ergonomics, and sense of embodiment. Robots need to have intrinsic knowledge of human feasible postures, quantitative metrics about ergonomics and dexterity - that give way to human reactivity and predictability when meeting manipulation challenges and uncertainties - and finally, quantitative metrics of muscular requirements to achieve given tasks. In this talk, I will present recent advances in human-based manipulability metrics, efficient human embodied structures to analyze them, methods to transfer manipulability features to robotic structures and tools to ground robot decision-making capabilities based on such human comfort-based manipulability metrics."
%}

{%
  include invited_speaker.html
  speakername="João Silveri"
  position="( Deutsches Zentrum für Luft- und Raumfahrt (DLR), Germany)"
  spekerlink="https://rmc.dlr.de/rm/en/staff/joao.silverio/"
  headline="Exploiting prior task knowledge for assistance during learning and shared control"

  text="To make robot skill acquisition quick and effective, a promising route is to use a combination of prior knowledge and data-driven methods. Such prior knowledge can take various forms depending on the problem at hand, including constraints (e.g. ’hold a cup upright if it is not empty’) and object-centered behaviors (e.g. ‘provide more assistance near the task goal’). Interestingly, the specification and handling thereof has been addressed independently in different fields, such as control and machine learning, raising the question of how they can benefit each other when coming together in robotic systems. In this talk I will show how shared control formulations, which implement task constraints as virtual fixtures, can be leveraged to make reinforcement learning in the real world safe and efficient. In the other direction this talk will demonstrate how concepts from machine learning, namely probabilistic models, can be adapted to suit the needs of shared control problems allowing, for instance, for an adaptive handling of virtual fixtures."
%}

***
## <i class="fas fa-edit"></i> **Acknowledgments**

The following **IEEE-RAS Technical Committees** have acknowledged the full support of the proposed workshop:   
- [IEEE-RAS TC on Human-Robot Interaction and Coordination](https://www.ieee-ras.org/human-robot-interaction-coordination)
- [IEEE-RAS TC on Wearable Robotics](https://www.ieee-ras.org/wearable-robotics)
- [IEEE-RAS TC on Collaborative Automation for Flexible Manufacturing](https://www.ieee-ras.org/collaborative-automation-for-flexible-manufacturing)
- [IEEE-RAS TC on Robot Learning](https://www.ieee-ras.org/robot-learning)


***

## <i class="fas fa-money-bill-wave-alt"></i> **Sponsorship**


*This workshop will be supported by the European Union’s Horizon 2020 research and innovation program under grant agreement No. 871237 (SOPHIA), and from the European Research Council program under grant agreement No. 850932 (Ergo-Lean).*


{%
  include feature.html
  image="images/event_img/sample/sponsor.png"
%}
